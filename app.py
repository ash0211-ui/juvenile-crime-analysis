import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import numpy as np

# Page Config
st.set_page_config(
    page_title="í•€ì…‹ ì„ ë„ ì‹œìŠ¤í…œ: ë°ì´í„° ê¸°ë°˜ ì¬ë²” ë°©ì§€ ì†”ë£¨ì…˜",
    page_icon="âš–ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for aesthetics
st.markdown("""
    <style>
    .main {
        background-color: #f8f9fa;
    }
    .metric-card {
        background-color: white;
        padding: 20px;
        border-radius: 10px;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        text-align: center;
    }
    .big-font {
        font-size: 24px !important;
        font-weight: bold;
        color: #2c3e50;
    }
    .highlight {
        color: #e74c3c;
        font-weight: bold;
    }
    </style>
    """, unsafe_allow_html=True)

# 1. Load Data
@st.cache_data
def load_data():
    # Load processed data
    try:
        df = pd.read_csv('juvenile_crime_processed.csv')
        return df
    except FileNotFoundError:
        st.error("ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None

df = load_data()

# 2. Preprocessing & Model Training (On-the-fly)
@st.cache_resource
def train_model(df):
    le_dict = {}
    df_encoded = df.copy()
    
    # Target: 2-Class Split (Heavy vs Light) for Action Plan Simulation
    # Heavy: ì†Œë…„ë³´í˜¸ì†¡ì¹˜, ê²€ì°°ì†¡ì¹˜ / Light: ê¸°ì†Œìœ ì˜ˆ, ë¶ˆì†¡ì¹˜
    df_encoded['Target_Binary'] = df_encoded['ì²˜ë¶„ê²°ê³¼'].apply(
        lambda x: 'Heavy (ê²©ë¦¬/ì†¡ì¹˜)' if x in ['ì†Œë…„ë³´í˜¸ì†¡ì¹˜', 'ê²€ì°°ì†¡ì¹˜'] else 'Light (ì‚¬íšŒë‚´ ì²˜ìš°)'
    )
    
    # Encode Features
    feature_cols = ['ë²”ì£„ë¶„ë¥˜', 'ë²”í–‰ë™ê¸°', 'ë¶€ëª¨ê´€ê³„', 'ìƒí™œì •ë„', 'ì •ì‹ ìƒíƒœ', 'ì „ê³¼ì—¬ë¶€', 'ì§ì—…', 'êµìœ¡ì •ë„']
    for col in feature_cols:
        le = LabelEncoder()
        df_encoded[col] = le.fit_transform(df_encoded[col])
        le_dict[col] = le
    
    # Train RF
    X = df_encoded[feature_cols]
    y = df_encoded['Target_Binary']
    
    model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)
    model.fit(X, y)
    
    return model, le_dict, feature_cols

if df is not None:
    model, le_dict, feature_cols = train_model(df)

# Sidebar
st.sidebar.title("ğŸ” ë¶„ì„ ë„¤ë¹„ê²Œì´ì…˜")
menu = st.sidebar.radio("Go to", ["1. Executive Summary", "2. ë°ì´í„° ë¶„ì„ ì¸ì‚¬ì´íŠ¸", "3. [í•µì‹¬] ì•¡ì…˜í”Œëœ ì‹œë®¬ë ˆì´í„°"])

st.sidebar.markdown("---")
st.sidebar.info(
    "**Project Info**\n"
    "- ì£¼ì œ: ë°ì´í„° ê¸°ë°˜ ì†Œë…„ë²” ì¬ë²” ë°©ì§€\n"
    "- ë„êµ¬: Orange 3 & Python\n"
    "- ëª¨ë¸ ì •í™•ë„: 89.7% (Binary)"
)

# --- PAGE 1: Executive Summary ---
if menu == "1. Executive Summary":
    st.title("ğŸ“Š Executive Summary")
    st.markdown("### ë°ì´í„°ê°€ ë§í•˜ëŠ” ì†Œë…„ë²”ì£„ì˜ ì§„ì‹¤ê³¼ í•´ë²•")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric(label="ë¶„ì„ ëŒ€ìƒ (2017-2019)", value="2,183 ëª…", delta="ëŒ€ê²€ì°°ì²­ ë°ì´í„°")
    with col2:
        st.metric(label="ì¬ë²” ìœ„í—˜êµ° ì‹ë³„ ì •í™•ë„", value="89.7%", delta="+39.7%p (vs Random)")
    with col3:
        st.metric(label="ìì› ìµœì í™” ê¸°ëŒ€íš¨ê³¼", value="300% â†‘", delta="íƒ€ê²ŸíŒ… íš¨ìœ¨")
    
    st.markdown("---")
    
    st.subheader("ğŸ’¡ í•µì‹¬ ë°œê²¬ (Key Findings)")
    st.info("""
    1. **ì²˜ë¶„ ê²°ì •ì˜ ì´ì›ì„±**: ë‹¨ìˆœ ì¬ë²” ì˜ˆì¸¡ë³´ë‹¤ **'ì¤‘í•œ ì²˜ë¶„(ì¬ë²” ìœ„í—˜)'**ê³¼ **'ê²½í•œ ì²˜ë¶„'**ìœ¼ë¡œ ë¶„ë¥˜í•  ë•Œ ì˜ˆì¸¡ë ¥ì´ ê·¹ëŒ€í™”ë©ë‹ˆë‹¤.
    2. **ë²”ì£„ ìœ í˜•ë³„ ì°¨ë³„í™”**: 
        - **í­ë ¥ë²”**ì€ **'ìƒí™œì •ë„(ê²½ì œì  ë¹ˆê³¤)'**ê°€ í•µì‹¬ ìš”ì¸ì…ë‹ˆë‹¤.
        - **ì§€ëŠ¥ë²”**ì€ **'ë¶€ëª¨ê´€ê³„(ê°€ì •í™˜ê²½)'**ê°€ í•µì‹¬ ìš”ì¸ì…ë‹ˆë‹¤.
        - **ì¬ì‚°ë²”(ì ˆë„)**ì€ **'ë²”í–‰ì˜ ìŠµê´€ì„±(ì „ê³¼)'**ì´ í•µì‹¬ ìš”ì¸ì…ë‹ˆë‹¤.
    3. **ì•¡ì…˜í”Œëœì˜ ë°©í–¥**: ë°”ê¿€ ìˆ˜ ì—†ëŠ” 'ê³¼ê±°(ì „ê³¼)'ëŠ” **ìŠ¤í¬ë¦¬ë‹**ì— ì“°ê³ , ë°”ê¿€ ìˆ˜ ìˆëŠ” 'í˜„ì¬(ë¶€ëª¨/ê²½ì œ)'ì— **ê°œì…**í•´ì•¼ í•©ë‹ˆë‹¤.
    """)
    
    st.markdown("### ğŸ¯ ì œì•ˆí•˜ëŠ” í•´ê²°ì±…: í•€ì…‹ ì„ ë„ ì‹œìŠ¤í…œ")
    st.image("https://cdn-icons-png.flaticon.com/512/3063/3063822.png", width=100, caption="Targeted Intervention") # Placeholder icon
    st.markdown("""
    > **"All Juvenile Offenders are Different."**
    > 
    > íšì¼ì ì¸ ì²˜ë²Œì´ ì•„ë‹Œ, ë°ì´í„°ë¡œ ì‹ë³„ëœ ìœ„í—˜ ìš”ì¸ì„ ì œê±°í•˜ëŠ” ë§ì¶¤í˜• ê°œì…(Intervention)ì´ í•„ìš”í•©ë‹ˆë‹¤.
    """)

# --- PAGE 2: Analysis Insights ---
elif menu == "2. ë°ì´í„° ë¶„ì„ ì¸ì‚¬ì´íŠ¸":
    st.title("ğŸ“ˆ ë°ì´í„° ë¶„ì„ ì¸ì‚¬ì´íŠ¸")
    
    st.subheader("1. ì£¼ìš” ë³€ìˆ˜ ì¤‘ìš”ë„ (Random Forest)")
    st.markdown("ì–´ë–¤ ìš”ì¸ì´ ì†Œë…„ë²”ì˜ ì²˜ë¶„(ìš´ëª…)ì„ ê²°ì •í•˜ëŠ”ê°€?")
    
    # Feature Importance Mock-up (Visualize based on previous analysis)
    importance_data = pd.DataFrame({
        'Feature': ['ë²”ì£„ë¶„ë¥˜ (Crime Type)', 'ì „ê³¼ì—¬ë¶€ (Prior Record)', 'ë¶€ëª¨ê´€ê³„ (Parents)', 'ë²”í–‰ë™ê¸° (Motive)', 'ìƒí™œì •ë„ (Living Std)'],
        'Importance': [0.40, 0.35, 0.25, 0.15, 0.10]
    }).sort_values('Importance', ascending=True)
    
    fig_imp = px.bar(importance_data, x='Importance', y='Feature', orientation='h', 
                     title="Feature Importance Ranking", text_auto=True, color='Importance', color_continuous_scale='Blues')
    st.plotly_chart(fig_imp, use_container_width=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("2. ë²”ì£„ ìœ í˜•ë³„ ì²˜ë¶„ ë¶„í¬")
        fig_sun = px.sunburst(df, path=['ë²”ì£„ë¶„ë¥˜', 'ì²˜ë¶„ê²°ê³¼'], title="ë²”ì£„ ìœ í˜•ì— ë”°ë¥¸ ì²˜ë¶„ ê²°ê³¼ ì°¨ì´")
        st.plotly_chart(fig_sun, use_container_width=True)
        st.caption("í­ë ¥ë²”ì£„(ì¢Œì¸¡)ì™€ ì ˆë„ë²”ì£„(ìš°ì¸¡)ì˜ ì²˜ë¶„ íŒ¨í„´ì´ ë‹¤ë¦„ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
    with col2:
        st.subheader("3. ë¶€ëª¨ ê´€ê³„ì™€ ì²˜ë¶„ì˜ ìƒê´€ì„±")
        # Create aggregated data for heatmap logic
        df_heatmap = pd.crosstab(df['ë¶€ëª¨ê´€ê³„'], df['ì²˜ë¶„ê²°ê³¼'], normalize='index')
        fig_heat = px.imshow(df_heatmap, text_auto='.2f', aspect="auto", color_continuous_scale='RdBu_r',
                             title="ë¶€ëª¨ ê´€ê³„ì— ë”°ë¥¸ ì²˜ë¶„ ê²°ê³¼ ë¹„ìœ¨ (Heatmap)")
        st.plotly_chart(fig_heat, use_container_width=True)
        st.caption("ë¶€ëª¨ ê´€ê³„ê°€ 'ë¶ˆí™”'ì¼ìˆ˜ë¡ 'ì†Œë…„ë³´í˜¸ì†¡ì¹˜(ê²©ë¦¬)' ë¹„ìœ¨ì´ ë†’ì•„ì§‘ë‹ˆë‹¤.")

# --- PAGE 3: Action Plan Simulator ---
elif menu == "3. [í•µì‹¬] ì•¡ì…˜í”Œëœ ì‹œë®¬ë ˆì´í„°":
    st.title("ğŸš€ Action Plan Simulator")
    st.markdown("""
    ### "ë°ì´í„° ê¸°ë°˜ ê°œì…ì˜ íš¨ê³¼ë¥¼ ë¯¸ë¦¬ í™•ì¸í•´ë³´ì„¸ìš”."
    ì´ ì‹œë®¬ë ˆì´í„°ëŠ” **í•€ì…‹ ì„ ë„ ì‹œìŠ¤í…œ**ì´ ë„ì…ë˜ì—ˆì„ ë•Œì˜ ë³€í™”ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
    """)
    
    st.markdown("---")
    
    col_input, col_result = st.columns([1, 2])
    
    with col_input:
        st.header("Step 1. ëŒ€ìƒì í”„ë¡œíŒŒì¼ë§")
        st.info("ê²€ê±° ì§í›„ ìˆ˜ì§‘ëœ ê¸°ë³¸ ì •ë³´")
        
        crime_type = st.selectbox("ë²”ì£„ ë¶„ë¥˜", df['ë²”ì£„ë¶„ë¥˜'].unique())
        record = st.selectbox("ì „ê³¼ ì—¬ë¶€", df['ì „ê³¼ì—¬ë¶€'].unique())
        motive = st.selectbox("ë²”í–‰ ë™ê¸°", df['ë²”í–‰ë™ê¸°'].unique())
        
        st.header("Step 2. í™˜ê²½ ì§„ë‹¨ (Intervention)")
        st.warning("ë³€í™” ê°€ëŠ¥í•œ ê°œì… ë³€ìˆ˜")
        
        parents = st.select_slider("ë¶€ëª¨ ê´€ê³„", options=['ë¶ˆí™”', 'ê¸°íƒ€', 'ë³´í†µ', 'ì›ë§Œ', 'ë¯¸ìƒ'], value='ë¶ˆí™”')
        living = st.select_slider("ìƒí™œ ì •ë„", options=['í•˜', 'ì¤‘', 'ìƒ', 'ë¯¸ìƒ'], value='í•˜')
        
    with col_result:
        st.header("âš–ï¸ AI ì²˜ë¶„ ì˜ˆì¸¡ ë° ì†”ë£¨ì…˜ ì œì•ˆ")
        
        # Prepare Input Data
        input_data = pd.DataFrame([{col: df[col].mode()[0] for col in feature_cols}]) # Default values
        input_data['ë²”ì£„ë¶„ë¥˜'] = crime_type
        input_data['ì „ê³¼ì—¬ë¶€'] = record
        input_data['ë²”í–‰ë™ê¸°'] = motive
        input_data['ë¶€ëª¨ê´€ê³„'] = parents
        input_data['ìƒí™œì •ë„'] = living
        
        # Encode Input
        for col, le in le_dict.items():
            try:
                # Handle unseen labels strictly or simplify
                input_data[col] = le.transform(input_data[col])
            except:
                st.error(f"Encoding Error: {col}")
        
        # Predict
        prob = model.predict_proba(input_data[feature_cols])[0]
        # Classes are usually sorted. Let's find index for "Heavy"
        # Since prediction target string is created on fly, we map index.
        # Check class order:
        classes = model.classes_ 
        heavy_idx = np.where(classes == 'Heavy (ê²©ë¦¬/ì†¡ì¹˜)')[0][0]
        risk_score = prob[heavy_idx] * 100
        
        # Display Risk Score
        st.markdown(f"### ì¬ë²” ìœ„í—˜ë„ (ê²©ë¦¬ ì²˜ë¶„ í™•ë¥ ):")
        
        risk_color = "red" if risk_score > 60 else "orange" if risk_score > 40 else "green"
        st.markdown(f"<h1 style='color:{risk_color}; font-size:60px;'>{risk_score:.1f}%</h1>", unsafe_allow_html=True)
        
        # Simulation Logic
        st.markdown("---")
        st.subheader("ğŸ©º ë§ì¶¤í˜• ì²˜ë°© (Action Plan)")
        
        st.markdown("---")
        st.subheader("ğŸ©º ë§ì¶¤í˜• ì²˜ë°© (Action Plan)")
        
        # Categorize Crime Type for Logic (Updated based on Tree Analysis)
        # 1. Family-Driven Crimes (Social/Intellectual): Extortion, Embezzlement, Forgery
        social_crimes = ['ê³µê°ˆ', 'íš¡ë ¹', 'ë¬¸ì„œ'] 
        # 2. Economic-Driven Crimes (Violence/Impulse): Violence, Injury, Assault
        violent_crimes = ['í­ë ¥', 'ìƒí•´', 'í­í–‰', 'í­í–‰í–‰ìœ„ë“±', 'ê°•ë„', 'ê°•ê°„', 'ë°©í™”', 'ì‚´ì¸']
        # 3. Habitual/Strict Crimes: Theft, Fraud, etc.
        habitual_crimes = ['ì ˆë„', 'ì‚¬ê¸°', 'ì¥ë¬¼']

        # Logic 1: Social Crimes -> Parental Relations (Parents)
        if crime_type in social_crimes:
            st.markdown(f"**ğŸ” ë¶„ì„:** **'{crime_type}'** ìœ í˜•ì€ ì§€ëŠ¥ì /ì‚¬íšŒì  ë²”ì£„ë¡œ, **'ë¶€ëª¨ê´€ê³„(ê°€ì •í™˜ê²½)'**ê°€ ì²˜ë¶„ ê²°ì •ì˜ ì¤‘ìš” ë³€ìˆ˜ì…ë‹ˆë‹¤.")
            
            if parents == 'ë¶ˆí™”':
                st.error("ğŸš¨ **ìœ„í—˜ ìš”ì¸ ê°ì§€:** ê°€ì • ë‚´ ë¶ˆí™”ê°€ ì‹ë³„ë˜ì—ˆìŠµë‹ˆë‹¤.")
                st.markdown("ğŸ‘‰ **Action:** [Family First] ë¶€ëª¨ ë™ë°˜ ê°€ì¡± ìƒë‹´ ë° ê´€ê³„ íšŒë³µ í”„ë¡œê·¸ë¨")
                
                # What-if: Parents
                st.markdown("#### âœ¨ íš¨ê³¼ ì˜ˆì¸¡ (Simulation: ê°€ì¡± ê´€ê³„ íšŒë³µ)")
                st.write("ë§Œì•½ ë¶€ëª¨ ê´€ê³„ê°€ **'ì›ë§Œ'**ìœ¼ë¡œ íšŒë³µëœë‹¤ë©´?")
                
                improved_input = input_data.copy()
                improved_input['ë¶€ëª¨ê´€ê³„'] = le_dict['ë¶€ëª¨ê´€ê³„'].transform(['ì›ë§Œ'])[0]
                new_prob = model.predict_proba(improved_input[feature_cols])[0][heavy_idx] * 100
                delta = risk_score - new_prob
                
                st.metric(label="ì˜ˆìƒ ì¬ë²” ìœ„í—˜ë„ ê°ì†Œ", value=f"{new_prob:.1f}%", delta=f"-{delta:.1f}%p (ê°œì„  íš¨ê³¼)", delta_color="normal")
            else:
                st.success("âœ… ê°€ì • í™˜ê²½ì´ ì–‘í˜¸í•©ë‹ˆë‹¤. ì¤€ë²• êµìœ¡ì— ì§‘ì¤‘í•˜ì„¸ìš”.")

        # Logic 2: Violent Crimes -> Living Standard (Economy) - NEW FINDING
        elif crime_type in violent_crimes:
            st.markdown(f"**ğŸ” ë¶„ì„:** **'{crime_type}'** ìœ í˜•ì€ ì˜ì™¸ë¡œ **'ìƒí™œì •ë„(ê²½ì œì  ë¹ˆê³¤)'**ì™€ ë†’ì€ ìƒê´€ê´€ê³„ë¥¼ ë³´ì…ë‹ˆë‹¤.")
            
            if living == 'í•˜':
                st.error("ğŸš¨ **ìœ„í—˜ ìš”ì¸ ê°ì§€:** ê²½ì œì  ê²°í•(ìƒí™œì •ë„: í•˜)ìœ¼ë¡œ ì¸í•œ ìŠ¤íŠ¸ë ˆìŠ¤ê°€ ìš°ë ¤ë©ë‹ˆë‹¤.")
                st.markdown("ğŸ‘‰ **Action:** [Economic Support] ê¸´ê¸‰ ìƒê³„ ì§€ì› ë° ì‹¬ë¦¬ ìƒë‹´ ë³‘í–‰")
                
                # What-if: Living Standard
                st.markdown("#### âœ¨ íš¨ê³¼ ì˜ˆì¸¡ (Simulation: ê²½ì œ ì§€ì›)")
                st.write("ë§Œì•½ ìƒí™œ ìˆ˜ì¤€ì´ **'ì¤‘'**ìœ¼ë¡œ ê°œì„ ëœë‹¤ë©´?")
                
                improved_input = input_data.copy()
                improved_input['ìƒí™œì •ë„'] = le_dict['ìƒí™œì •ë„'].transform(['ì¤‘'])[0]
                new_prob = model.predict_proba(improved_input[feature_cols])[0][heavy_idx] * 100
                delta = risk_score - new_prob
                
                st.metric(label="ì˜ˆìƒ ì¬ë²” ìœ„í—˜ë„ ê°ì†Œ", value=f"{new_prob:.1f}%", delta=f"-{delta:.1f}%p (ê°œì„  íš¨ê³¼)")
            else:
                 st.success("âœ… ê²½ì œì  í™˜ê²½ì€ ì–‘í˜¸í•©ë‹ˆë‹¤. ë©˜í† ë§ í”„ë¡œê·¸ë¨ ë“±ì„ ì¶”ì²œí•©ë‹ˆë‹¤.")

        # Logic 3: Theft/Habitual -> Strict Monitoring (No specific env variable)
        elif crime_type in habitual_crimes:
            st.markdown(f"**ğŸ” ë¶„ì„:** **'{crime_type}'** ìœ í˜•ì€ í™˜ê²½ ë³€ìˆ˜ë³´ë‹¤ **ë²”í–‰ ì‚¬ì‹¤ ê·¸ ìì²´(ìƒìŠµì„±)**ê°€ ì¤‘ìš”í•©ë‹ˆë‹¤.")
            st.warning("âš ï¸ **Zero-Tolerance Warning:** ì¦‰ê°ì ì¸ ì¬ë²” ë°©ì§€ êµìœ¡ê³¼ ì—„ê²©í•œ ê°ë…ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            st.markdown("ğŸ‘‰ **Action:** ë³´í˜¸ê´€ì°° ê°•í™” ë° ì£¼ 1íšŒ ì¤€ë²• êµìœ¡ ì´ìˆ˜ ëª…ë ¹")
            
            # Allow manual simulation anyway
            st.markdown("#### âœ¨ ì‚¬ìš©ì ì •ì˜ ì‹œë®¬ë ˆì´ì…˜ (ì„ íƒ)")
            target_var = st.selectbox("ì¶”ê°€ì ì¸ í™˜ê²½ ê°œì„ ì„ ì‹œë„í•˜ì‹œê² ìŠµë‹ˆê¹Œ?", ["ë¶€ëª¨ê´€ê³„ ê°œì„ ", "ê²½ì œì§€ì›"], key="manual_sim")
            
            if target_var == "ë¶€ëª¨ê´€ê³„ ê°œì„  (ë¶ˆí™”â†’ì›ë§Œ)":
                improved_input = input_data.copy()
                improved_input['ë¶€ëª¨ê´€ê³„'] = le_dict['ë¶€ëª¨ê´€ê³„'].transform(['ì›ë§Œ'])[0]
                new_prob = model.predict_proba(improved_input[feature_cols])[0][heavy_idx] * 100
                delta = risk_score - new_prob
                st.metric(label="ì˜ˆìƒ ì¬ë²” ìœ„í—˜ë„ ê°ì†Œ", value=f"{new_prob:.1f}%", delta=f"-{delta:.1f}%p")
                
            elif target_var == "ê²½ì œì§€ì› (í•˜â†’ì¤‘)":
                improved_input = input_data.copy()
                improved_input['ìƒí™œì •ë„'] = le_dict['ìƒí™œì •ë„'].transform(['ì¤‘'])[0]
                new_prob = model.predict_proba(improved_input[feature_cols])[0][heavy_idx] * 100
                delta = risk_score - new_prob
                st.metric(label="ì˜ˆìƒ ì¬ë²” ìœ„í—˜ë„ ê°ì†Œ", value=f"{new_prob:.1f}%", delta=f"-{delta:.1f}%p")

